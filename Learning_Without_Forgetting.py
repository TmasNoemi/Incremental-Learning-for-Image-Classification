# -*- coding: utf-8 -*-
"""Learning_Without_Forgetting.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sJ9kaLC_fhQ9uVcBaaijkt3thMQbcwjb
"""

import os
import logging
import torch
import torchvision
import numpy as np
import pandas as pd
import copy
import os.path
import sys
import random
import time
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torch.nn.init as init
from torch.utils.data import Subset, DataLoader
from torch.backends import cudnn
from torch.autograd import Variable
from torchvision.datasets import VisionDataset
from torchvision import transforms, datasets
from PIL import Image
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import matplotlib as mlp
import seaborn as sns
from model import resnet32
from seed import seed

sns.set()

class LwF(nn.Module):
  def __init__(self, n_classes, dictionary):
    super(LwF, self).__init__()

    self.model = resnet32()
    self.prev_model = None
    self.d = dictionary
    self.num_epochs = 70
    self.optimizer = optim.SGD(self.model.parameters(), lr=2, momentum=0.9, weight_decay=1e-5)
    self.scheduler = optim.lr_scheduler.MultiStepLR(self.optimizer,[49,63], gamma=0.2)
    self.criterion = nn.BCEWithLogitsLoss()

    self.n_classes = n_classes
    self.bs = n_classes

  def update_model(self):
    self.prev_model = copy.deepcopy(self.model)
    self.model.fc = nn.Linear(64, self.n_classes + self.bs)
    self.model.fc.weight.data[0: self.n_classes] = self.prev_model.fc.weight.data
    self.model.fc.bias.data[0: self.n_classes] = self.prev_model.fc.bias.data

  def forward(self, x):
    x = self.model(x) 
    return x

  def train_model(self, dataloader):
    loss_array = []
    self.model = self.model.cuda()
    cudnn.benchmark
    
    start = time.time()
    optimizer = self.optimizer
    scheduler = self.scheduler
    
    for epoch in range(self.num_epochs):
        print('Epoch {}/{}'.format(epoch+1, self.num_epochs))
        print('-' * 10)

        self.model.train() 
        
        running_loss = 0.0
        running_corrects = 0
        for images, labels in dataloader:
            
              labels_map = [d[label.item()] for label in labels]         
              labels_map = torch.as_tensor(labels_map)            
              images = images.cuda()
              labels_map = labels_map.cuda()           
              optimizer.zero_grad()
              if self.prev_model == None:              
                outputs = self.model(images)
                one_hot = nn.functional.one_hot(labels_map, self.n_classes)
                one_hot = one_hot.type_as(outputs)       
                _, preds = torch.max(outputs.data, 1)
                loss = self.criterion(outputs, one_hot)
                loss.backward()
                optimizer.step()

                running_loss += loss.item() * images.size(0)
                running_corrects += torch.sum(preds == labels_map.data).data.item()
              else:
                outputs = self.model(images)                     
                self.prev_model.train(False)
                old_outputs = self.prev_model(images)
                one_hot = nn.functional.one_hot(labels_map, self.n_classes + self.bs)
                one_hot = one_hot.type_as(outputs)

                _, preds = torch.max(outputs.data, 1)
                _, old_preds = torch.max(old_outputs.data,1)
                old_outputs = torch.sigmoid(old_outputs)

                targets = torch.cat((old_outputs, one_hot[:,self.n_classes-self.bs:self.n_classes]),1)
                loss = self.criterion(outputs, targets)
                loss.backward()
                optimizer.step()
                running_loss += loss.item() * images.size(0)
                running_corrects += torch.sum(preds == labels_map.data).data.item() #accuracy on new classes 

        del images, labels
        torch.cuda.empty_cache()

        epoch_loss = running_loss / float(len(dataloader.dataset))
        epoch_acc = running_corrects/ float(len(dataloader.dataset))
        loss_array.append(epoch_loss)
        scheduler.step()

        print('Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))
        print()

    time_elapsed = time.time() - start
    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))

  def test_model(self,dataloader):
    self.model = self.model.cuda() 
    
    self.model.train(False)
    running_corrects = 0
    corrects = []
    predictions = []

    for images, labels in dataloader:

        labels_map = [d[label.item()] for label in labels]     
        labels_map = torch.as_tensor(labels_map)
        images = images.cuda()
        labels_map = labels_map.cuda()

        outputs = self.model(images)
        _, preds = torch.max(outputs.data, 1)    
        running_corrects += torch.sum(preds == labels_map.data).data.item()
        
        for lab,pred in zip(labels_map, preds):
          corrects.append(lab.item())
          predictions.append(pred.item())

    accuracy = running_corrects / float(len(dataloader.dataset))   
    confmat = confusion_matrix(corrects, predictions)
    print_confusion_matrix(confmat, set(corrects))
    torch.cuda.empty_cache()
    plt.show()
    
    print('Test Accuracy: {}'.format(accuracy))
    return accuracy

def print_confusion_matrix(confusion_matrix, class_names, figsize = (6,4), fontsize=5):
      df_cm = pd.DataFrame(
          confusion_matrix, index=class_names, columns=class_names, 
      )
      fig = plt.figure(figsize=figsize)
      try:
          cmap = plt.get_cmap('jet')
          new_cmap = truncate_colormap(cmap, 0.05, 0.85)
          heatmap = sns.heatmap(df_cm, annot=False, fmt="d", cmap = new_cmap)
      except ValueError:
          raise ValueError("Confusion matrix values must be integers.")
      heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)
      heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)
      plt.ylabel('True label')
      plt.xlabel('Predicted label')
      plt.show()
      return fig
def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):
      new_cmap = mlp.colors.LinearSegmentedColormap.from_list(
          'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),
          cmap(np.linspace(minval, maxval, n)))
      return new_cmap

train_transform=transforms.Compose([
            transforms.RandomCrop(32,padding = 4),
            transforms.RandomHorizontalFlip(p=0.5),         
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

test_transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

trainset = torchvision.datasets.CIFAR100(root='./data', train=True,
                                        download=True, transform=train_transform)

testset = torchvision.datasets.CIFAR100(root='./data', train=False,
                                       download=True, transform=test_transform)

d = {seed[i]:i for i in range(len(seed))}

#creating the batches of data for different groups of 10 classes
batches_train = []
batches_test = []

for i in range(10,110,10):
  x = seed[i-10:i]
  y = seed[0:i]
  idx_train = [i for i,el in enumerate(trainset.targets) if el in x]
  batches_train.append(Subset(trainset,idx_train))
  idx_test = [j for j, el in enumerate(testset.targets) if el in y]
  batches_test.append(Subset(testset, idx_test))


train_dataloaders = [DataLoader(batch, batch_size=128, shuffle=False, num_workers=4) for batch in batches_train]
test_dataloaders = [DataLoader(batch, batch_size=128, shuffle=True, num_workers=4) for batch in batches_test]

cum_acc = np.zeros(10)
#initialize the class Learning without Forgetting
lwf = LwF(10,d)

for batch,classes in enumerate(range(10,110,10)):

  lwf.n_classes = classes
  print(f'Number of classes: {classes}')
  lwf.train_model(train_dataloaders[batch])
  acc = lwf.test_model(test_dataloaders[batch])
  cum_acc[batch] = acc
  lwf.update_model()